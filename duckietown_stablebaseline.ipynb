{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "duckietown_stablebaseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPSehmf4sg/osXNVa+aGijR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuliovv/airbullet/blob/master/duckietown_stablebaseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWs-smIR_BD8"
      },
      "source": [
        "#Train duckietown with stable baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6gF4aXa_GQx"
      },
      "source": [
        "Environment setup "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnPw8GUh-IGW",
        "outputId": "5fcf59b0-99cc-43d5-ca7a-7ee9c669996b"
      },
      "source": [
        "import os \n",
        "if not os.path.isdir('gym-duckietown') and not os.path.isdir('../gym-duckietown'):\n",
        "  branch = \"master\" #@param ['master', 'daffy']\n",
        "  !git clone --branch {branch} https://github.com/duckietown/gym-duckietown.git\n",
        "  !pip3 install -e gym-duckietown\n",
        "if \"/gym-duckietown\" not in os.getcwd():\n",
        "  os.chdir('gym-duckietown')\n",
        "!apt install xvfb -y\n",
        "!pip3 install pyvirtualdisplay\n",
        "from pyvirtualdisplay import Display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gym-duckietown'...\n",
            "remote: Enumerating objects: 5528, done.\u001b[K\n",
            "remote: Total 5528 (delta 0), reused 0 (delta 0), pack-reused 5528\u001b[K\n",
            "Receiving objects: 100% (5528/5528), 79.01 MiB | 16.45 MiB/s, done.\n",
            "Resolving deltas: 100% (3219/3219), done.\n",
            "Obtaining file:///content/gym-duckietown\n",
            "Requirement already satisfied: gym>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from gym-duckietown==2019.0.0) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from gym-duckietown==2019.0.0) (1.19.5)\n",
            "Requirement already satisfied: pyglet in /usr/local/lib/python3.6/dist-packages (from gym-duckietown==2019.0.0) (1.5.0)\n",
            "Requirement already satisfied: pyzmq>=16.0.0 in /usr/local/lib/python3.6/dist-packages (from gym-duckietown==2019.0.0) (22.0.2)\n",
            "Requirement already satisfied: scikit-image>=0.13.1 in /usr/local/lib/python3.6/dist-packages (from gym-duckietown==2019.0.0) (0.16.2)\n",
            "Requirement already satisfied: opencv-python>=3.4 in /usr/local/lib/python3.6/dist-packages (from gym-duckietown==2019.0.0) (4.1.2.30)\n",
            "Requirement already satisfied: pyyaml>=3.11 in /usr/local/lib/python3.6/dist-packages (from gym-duckietown==2019.0.0) (3.13)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from gym-duckietown==2019.0.0) (1.3.0)\n",
            "Collecting duckietown_slimremote>=2018.8.2\n",
            "  Downloading https://files.pythonhosted.org/packages/66/0d/269674f3e7bcb85c7981d5a3eb4d6c734f6d3755f0db07b9d92f1c108f9d/duckietown_slimremote-2018.10.1.tar.gz\n",
            "Collecting pygeometry\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/83/aa9c265062048bf8fb647631ef836c2cbef55c7e5e61a8f72c7c38adb774/PyGeometry-1.5.6.tar.gz (220kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from gym-duckietown==2019.0.0) (0.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym>=0.9.0->gym-duckietown==2019.0.0) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet->gym-duckietown==2019.0.0) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.13.1->gym-duckietown==2019.0.0) (7.0.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.13.1->gym-duckietown==2019.0.0) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.13.1->gym-duckietown==2019.0.0) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.13.1->gym-duckietown==2019.0.0) (2.5)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.13.1->gym-duckietown==2019.0.0) (2.4.1)\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/pycontracts/\u001b[0m\n",
            "Collecting PyContracts<2,>=1.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/7a/0f79370e4e3a6741396d76d1f76586c2924bed049fb38597799b72a24081/PyContracts-1.8.12.tar.gz (91kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.13.1->gym-duckietown==2019.0.0) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.13.1->gym-duckietown==2019.0.0) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.13.1->gym-duckietown==2019.0.0) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.13.1->gym-duckietown==2019.0.0) (2.4.7)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.13.1->gym-duckietown==2019.0.0) (4.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from PyContracts<2,>=1.5->pygeometry->gym-duckietown==2019.0.0) (1.15.0)\n",
            "Building wheels for collected packages: duckietown-slimremote, pygeometry, PyContracts\n",
            "  Building wheel for duckietown-slimremote (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for duckietown-slimremote: filename=duckietown_slimremote-2018.10.1-cp36-none-any.whl size=1522 sha256=6c94b0ec3c60cf7a439801b6715fd831279b4daa5079528c2d4a27e1a794ca68\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/b7/45/f23813d245dd37135151cdac7c098b81f9636d2ae64320f832\n",
            "  Building wheel for pygeometry (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygeometry: filename=PyGeometry-1.5.6-cp36-none-any.whl size=68837 sha256=f6adedc4931663d2884128ceabf9d296edac61abb24b87ba7f446ce72abfe4be\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/c1/e4/c1fca68a862dd2d38d7b905b8c8931f9a8863cdf736c607aeb\n",
            "  Building wheel for PyContracts (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyContracts: filename=PyContracts-1.8.12-cp36-none-any.whl size=89638 sha256=fd6d2b7cc10df5c3cb488c0a6ea0d5fbed5594737d16804168db1ef81346d5b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/42/54/0a9c2dcc4b90546d40215817d7c723f99a4ab16da637be9539\n",
            "Successfully built duckietown-slimremote pygeometry PyContracts\n",
            "Installing collected packages: duckietown-slimremote, PyContracts, pygeometry, gym-duckietown\n",
            "  Running setup.py develop for gym-duckietown\n",
            "Successfully installed PyContracts-1.8.12 duckietown-slimremote-2018.10.1 gym-duckietown pygeometry-1.5.6\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,270 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.8 [784 kB]\n",
            "Fetched 784 kB in 2s (354 kB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWHDICC-_Mjo"
      },
      "source": [
        "Install stable baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii2w84aUBL6x"
      },
      "source": [
        "# Stable baseline requires tensorflow 1.x\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSVnMupWErAZ"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vze9xU8-PZK"
      },
      "source": [
        "!apt update && apt install cmake libopenmpi-dev python3-dev zlib1g-dev\n",
        "!pip3 install stable-baselines[mpi]\n",
        "#This version with mpi is apparently broken, see:\n",
        "#https://github.com/hill-a/stable-baselines/issues/464\n",
        "!pip3 install stable-baselines --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckktk_4CreKz"
      },
      "source": [
        "map_name = \"Duckietown-small_loop-v0\" #@param ['Duckietown-straight_road-v0','Duckietown-4way-v0','Duckietown-udem1-v0','Duckietown-small_loop-v0','Duckietown-small_loop_cw-v0','Duckietown-zigzag_dists-v0','Duckietown-loop_obstacles-v0','Duckietown-loop_pedestrians-v0']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOWXCpQqPelZ"
      },
      "source": [
        "Wrapper to highlight lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogq5yEuS2aer"
      },
      "source": [
        "import cv2\n",
        "import gym\n",
        "from gym.spaces import Box\n",
        "\n",
        "cutted_img_height = 350 #@param {type: \"slider\", min: 0, max: 480, step:1}\n",
        "resize_ratio = 0.35 #@param {type: \"slider\", min: 0.0, max: 1.0, step:0.01}\n",
        "\n",
        "img_height = 480\n",
        "top_crop = img_height - cutted_img_height\n",
        "\n",
        "img_final_height = int(cutted_img_height * resize_ratio)\n",
        "img_final_width = int(640 * resize_ratio)\n",
        "\n",
        "def cropimg(img):\n",
        "    \"\"\"\n",
        "    Crop top of image top_crop px, they are noise most of the time\n",
        "\n",
        "    :param img: (RGB image as np array) Image to be cropped\n",
        "    \"\"\"\n",
        "    return img[top_crop:,:]\n",
        "\n",
        "def houghtransform(img):\n",
        "    \"\"\"\n",
        "    Apply Hough Line transform, for theory see:\n",
        "    https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_houghlines/py_houghlines.html\n",
        "\n",
        "    :param img: (RGB image as np array)\n",
        "    \"\"\"\n",
        "    frame_BGR = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    #gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY, 3)\n",
        "    edges = cv2.Canny(frame_BGR,50,150,apertureSize = 3)\n",
        "    #minLineLength = 100\n",
        "    #maxLineGap = 10\n",
        "    #lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength,maxLineGap)\n",
        "    #for x1,y1,x2,y2 in lines[0]:\n",
        "    #    cv2.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "    imgRGB = cv2.cvtColor(edges, cv2.COLOR_BGR2RGB)\n",
        "    return imgRGB\n",
        "\n",
        "def resizeimg(img, ratio):\n",
        "    \"\"\"\n",
        "    Resize image\n",
        "    :param img: (np array)\n",
        "    :param ratio: (float) 0<ratio<1\n",
        "    \"\"\"\n",
        "    return cv2.resize(img, (0,0), fx=ratio, fy=ratio) \n",
        "  \n",
        "def takeyellow(img):\n",
        "    \"\"\"\n",
        "    Extract yellow lines, for color ranges see:\n",
        "    https://stackoverflow.com/questions/48109650/how-to-detect-two-different-colors-using-cv2-inrange-in-python-opencv\n",
        "\n",
        "    :param img: (RGB image as np array)\n",
        "    \"\"\"\n",
        "    frame_HSV = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "    frame_threshold = cv2.inRange(frame_HSV, (20,100,100), (50, 255, 255))\n",
        "    imgRGB = cv2.cvtColor(frame_threshold, cv2.COLOR_GRAY2RGB)\n",
        "    return imgRGB\n",
        "\n",
        "def takewhiteyellow(img):\n",
        "    \"\"\"\n",
        "    Extract white and yellow lines\n",
        "\n",
        "    :param img: (RGB image as np array)\n",
        "    \"\"\"\n",
        "    #white\n",
        "    sensitivity = 100\n",
        "    lower_white = np.array([0,0,255-sensitivity])\n",
        "    upper_white = np.array([255,sensitivity,255])\n",
        "    frame_HSV = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "    maskwhite = cv2.inRange(frame_HSV, lower_white, upper_white)\n",
        "    img[maskwhite > 0] = (255, 0, 0)\n",
        "    img[maskwhite == 0] = (0,0,0)\n",
        "    #yellow\n",
        "    maskyellow = cv2.inRange(frame_HSV, (15,70,70), (50, 255, 255))\n",
        "    img[maskyellow > 0] = (0, 255, 0)\n",
        "    return img\n",
        "\n",
        "def white_balance(img):\n",
        "    \"\"\"\n",
        "    Grayworld assumption:\n",
        "    https://stackoverflow.com/questions/46390779/automatic-white-balancing-with-grayworld-assumption/46391574\n",
        "\n",
        "    :param img: (RGB image as np array)\n",
        "    \"\"\"\n",
        "    result = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
        "    avg_a = np.average(result[:, :, 1])\n",
        "    avg_b = np.average(result[:, :, 2])\n",
        "    result[:, :, 1] = result[:, :, 1] - ((avg_a - 128) * (result[:, :, 0] / 255.0) * 1.1)\n",
        "    result[:, :, 2] = result[:, :, 2] - ((avg_b - 128) * (result[:, :, 0] / 255.0) * 1.1)\n",
        "    result = cv2.cvtColor(result, cv2.COLOR_LAB2RGB)\n",
        "    return result\n",
        "\n",
        "class ObsWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(ObsWrapper, self).__init__(env)\n",
        "        self.observation_space = Box(0, 255, (img_final_height, img_final_width, 3), dtype=self.observation_space.dtype)\n",
        "        self.accept_start_angle_deg = 4\n",
        "        self.env = env\n",
        "\n",
        "    def observation(self, obs):\n",
        "        cropped = cropimg(obs)\n",
        "        resized = resizeimg(cropped, resize_ratio)\n",
        "        balanced = white_balance(resized)\n",
        "        img = takewhiteyellow(balanced)\n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDmisuT60rpI"
      },
      "source": [
        "class NormalizeWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(NormalizeWrapper, self).__init__(env)\n",
        "        self.observation_space = Box(0, 1, self.observation_space.shape, dtype=self.observation_space.dtype)\n",
        "        self.env = env\n",
        "\n",
        "    def observation(self, obs):\n",
        "        obs = obs/255\n",
        "        return obs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVzrES9nRTAH"
      },
      "source": [
        "Wrapper result example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq12N95MPdap"
      },
      "source": [
        "import gym_duckietown\n",
        "\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "env = gym.make(map_name, accept_start_angle_deg=4)\n",
        "env = ObsWrapper(env)\n",
        "plt.imshow(env.reset())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZm-kw82y2bJ"
      },
      "source": [
        "env = NormalizeWrapper(env)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcbHX4R8XWXO"
      },
      "source": [
        "env.observation_space"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lly9fjlv9UqS"
      },
      "source": [
        "env.action_space"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-trsYF4E_SG"
      },
      "source": [
        "%tensorboard --logdir ./a2c_duckieloop/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndNCPWQEM43x"
      },
      "source": [
        "NB Con lr = 0.0007 e gamma >= 0.6 reward converge a -1000, con 0.5 esce la situazione reward = 0 e la macchina fa retromarcia invece di curvare\n",
        "\n",
        "Con lr = 0.007 e gamma = 0.5 converge a -1000 nei primi 30k (CnnLstm)\n",
        "\n",
        "Con lr = 0.00007 e gamma 0.5 fa ancora retromarcia invece di curvare con 200k, con gamma 0.6 e 0.05 uguale. (CnnLstm)\n",
        "\n",
        "Con lr = 0.00007 e gamma 0.4 fa ancora retromarcia ma curva un po' curvare con 200k, ma i mean reward nel train sono piuttosto alti (>-600). (CnnLstm)\n",
        "\n",
        "0.3 come 0.4 ma reward non buoni\n",
        "\n",
        "0.1 schifo\n",
        "\n",
        "0.2 non fa neanche i rettilinei"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP7ebYLq--KF"
      },
      "source": [
        "from stable_baselines.common.vec_env import VecFrameStack\n",
        "from stable_baselines import A2C\n",
        "from stable_baselines.common.policies import CnnLstmPolicy\n",
        "from stable_baselines.common.evaluation import evaluate_policy\n",
        " \n",
        "model = A2C(\n",
        "    CnnLstmPolicy,\n",
        "    env,\n",
        "    gamma=0.3, #Discount reward def=0.99\n",
        "    n_steps=5,\n",
        "    learning_rate=0.00007, #def=0.0007\n",
        "    lr_schedule='constant',\n",
        "    verbose=0,\n",
        "    tensorboard_log=\"./a2c_duckieloop/\"\n",
        "    )\n",
        " \n",
        "# Change range to train more\n",
        "if False:\n",
        "  print(\"Starting...\")\n",
        "  for time in range(10):\n",
        "    model.learn(total_timesteps=int(2e4))\n",
        "    model.save(\"a2c\"+map_name+str(1e4*time))\n",
        "    mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
        "    print(f\"#{time} Trained 10000 timesteps, mean_reward: {mean_reward}, std_reward: {std_reward}\")\n",
        "  \n",
        "  ipythondisplay.clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-O0qmH1Gw2u"
      },
      "source": [
        "# Set up fake display; otherwise rendering will fail\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xla7TYKpGx3s"
      },
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "def show_videos(video_path='', prefix=''):\n",
        "  \"\"\"\n",
        "  Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "  :param video_path: (str) Path to the folder containing videos\n",
        "  :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "  \"\"\"\n",
        "  html = []\n",
        "  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "      video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "      html.append('''<video alt=\"{}\" autoplay \n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0EYf0nsGy8D"
      },
      "source": [
        "from stable_baselines.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
        "\n",
        "def record_video(model, video_length=500, prefix='', video_folder='videos/'):\n",
        "  \"\"\"\n",
        "  :param model: (RL model)\n",
        "  :param video_length: (int)\n",
        "  :param prefix: (str)\n",
        "  :param video_folder: (str)\n",
        "  \"\"\"\n",
        "  eval_env = DummyVecEnv([lambda: NormalizeWrapper(ObsWrapper(gym.make(map_name, accept_start_angle_deg=4)))])\n",
        "  # Start the video at step=0 and record 500 steps\n",
        "  eval_env = VecVideoRecorder(eval_env, video_folder=video_folder,\n",
        "                              record_video_trigger=lambda step: step == 0, video_length=video_length,\n",
        "                              name_prefix=prefix)\n",
        "\n",
        "  obs = eval_env.reset()\n",
        "  for _ in range(video_length):\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, reward, done, _ = eval_env.step(action)\n",
        "    if done and reward < 0:\n",
        "      print(\"*** CRASHED ***\")\n",
        "      print(reward)\n",
        "    elif done:\n",
        "      print(\"SAFE\")\n",
        "      print(reward)\n",
        "    \n",
        "\n",
        "  # Close the video recorder\n",
        "  eval_env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGXCFrCJHMCF"
      },
      "source": [
        "if False:\n",
        "    time = 4\n",
        "    model_to_be_loaded = \"a2c\"+map_name+str(1e4*time)\n",
        "    model = A2C.load(model_to_be_loaded)\n",
        "if False:\n",
        "  record_video(model, video_length=500, prefix=map_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9IFe9EfHV39"
      },
      "source": [
        "if False:\n",
        "  show_videos('videos', prefix=map_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzzIyKuHq4So"
      },
      "source": [
        "# To continue the training set to True\n",
        "if False:\n",
        "  # To load a model set to True\n",
        "  if False:\n",
        "    from stable_baselines import A2C\n",
        "    model_to_be_loaded = \"a2c\"+map_name+\"\"\n",
        "    model = A2C.load(model_to_be_loaded, tensorboard_log=\"./a2c_duckieloop/\")\n",
        "    model.set_env(env)\n",
        "  for time in range(5):\n",
        "    model.learn(total_timesteps=int(1e5))\n",
        "    model.save(\"a2c\"+map_name+str(1e5*time))\n",
        "    mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
        "    print(f\"Trained 100000 timesteps, mean_reward: {mean_reward}, std_reward: {std_reward}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zbL74H6pmGR"
      },
      "source": [
        "Test parameter search using optuna:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJJUABxCoFmn"
      },
      "source": [
        "def objective(trial):\n",
        "\n",
        "    gamma = trial.suggest_float(\"gamma\", 0.5, 0.6)\n",
        "\n",
        "    model = A2C(\n",
        "      CnnLstmPolicy,\n",
        "      env,\n",
        "      gamma=gamma,\n",
        "      n_steps=5,\n",
        "      learning_rate=0.00007, #def=0.0007\n",
        "      lr_schedule='constant',\n",
        "      verbose=0,\n",
        "      tensorboard_log=\"./a2c_duckieloop/\"\n",
        "    )\n",
        "\n",
        "    model.learn(total_timesteps=int(5e4))\n",
        "    mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=100)\n",
        "    print(gamma)\n",
        "    print(mean_reward)\n",
        "\n",
        "    return mean_reward\n",
        "\n",
        "if True:\n",
        "  !pip install optuna\n",
        "  import optuna\n",
        "  study = optuna.create_study(direction='maximize')\n",
        "  study.optimize(objective, n_trials=20)\n",
        "  print(study.best_params)\n",
        "  print(study.best_value)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}